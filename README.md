# üß≠ ContextPilot

An AI-powered personal context engine that automatically builds and maintains a structured "memory" of a user's projects, decisions, preferences, and knowledge‚Äîthen injects the right context into future AI prompts, emails, documents, or code tasks.

## üéØ What is ContextPilot?

Most AI tools are stateless‚Äîthey forget context between sessions. ContextPilot solves this by:

- **Storing structured context** (preferences, decisions, goals, facts) with versioning
- **Ranking context by relevance** using semantic embeddings
- **Generating optimized prompts** that automatically include the right context
- **Providing a clean UI** to manage your personal knowledge base

## ‚ú® Features

- ‚úÖ **CRUD operations** for context units
- ‚úÖ **Persistent storage** with SQLite or PostgreSQL + pgvector
- ‚úÖ **AI integration** with OpenAI (GPT-4) and Anthropic (Claude)
- ‚úÖ **Conversation history** with automatic persistence
- ‚úÖ **Semantic search** using sentence-transformers embeddings
- ‚úÖ **Embedding caching** for faster similarity searches
- ‚úÖ **Response caching** for improved API performance
- ‚úÖ **Confidence scoring** and versioning
- ‚úÖ **Relevance engine** that ranks contexts by task relevance
- ‚úÖ **Prompt composer** that generates LLM-ready prompts
- ‚úÖ **Clean React UI** for managing context and viewing prompts
- ‚úÖ **RESTful API** with FastAPI and OpenAPI documentation
- ‚úÖ **Security features** - API key auth, input validation, CORS, rate limiting
- ‚úÖ **Request tracking** with unique IDs and timing
- ‚úÖ **Structured logging** with JSON output option
- ‚úÖ **Database migrations** with Alembic
- ‚úÖ **No external dependencies** for embeddings (uses local models)
- ‚úÖ **Context Import/Export** - JSON/CSV export and JSON import functionality
- ‚úÖ **Advanced Filtering** - Search by type, tags, content, and status
- ‚úÖ **Context Templates** - Quick creation with 6 pre-defined templates
- ‚úÖ **Mobile Responsive UI** - Optimized for mobile devices  
- ‚úÖ **Enhanced UX** - Loading states, smooth transitions, and improved interactions
- ‚úÖ **Settings Management** - Configure API keys and AI parameters directly in the UI

## üèóÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   React UI      ‚îÇ  ‚Üê User Interface
‚îÇ  (TypeScript)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
    HTTP REST API
         ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  FastAPI Server ‚îÇ  ‚Üê Backend
‚îÇ                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ Storage   ‚îÇ  ‚îÇ  ‚Üê SQLite/PostgreSQL or in-memory
‚îÇ  ‚îÇ (Database)‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ Relevance ‚îÇ  ‚îÇ  ‚Üê Embedding-based ranking
‚îÇ  ‚îÇ  Engine   ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Prompt   ‚îÇ  ‚îÇ  ‚Üê Context composition
‚îÇ  ‚îÇ Composer  ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇAI Service ‚îÇ  ‚îÇ  ‚Üê OpenAI / Anthropic
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üìÅ Project Structure

```
ContextPilot/
‚îú‚îÄ‚îÄ backend/                 # FastAPI backend server
‚îÇ   ‚îú‚îÄ‚îÄ main.py              # FastAPI application entry point
‚îÇ   ‚îú‚îÄ‚îÄ models.py            # Pydantic data models
‚îÇ   ‚îú‚îÄ‚îÄ db_models.py         # SQLAlchemy database models
‚îÇ   ‚îú‚îÄ‚îÄ storage.py           # In-memory context store
‚îÇ   ‚îú‚îÄ‚îÄ db_storage.py        # Database storage implementation
‚îÇ   ‚îú‚îÄ‚îÄ storage_interface.py # Storage abstraction layer
‚îÇ   ‚îú‚îÄ‚îÄ relevance.py         # Semantic search & ranking
‚îÇ   ‚îú‚îÄ‚îÄ composer.py          # Prompt composition engine
‚îÇ   ‚îú‚îÄ‚îÄ ai_service.py        # OpenAI/Anthropic integration
‚îÇ   ‚îú‚îÄ‚îÄ config.py            # Configuration management
‚îÇ   ‚îú‚îÄ‚îÄ security.py          # Authentication & validation
‚îÇ   ‚îú‚îÄ‚îÄ database.py          # Database session management
‚îÇ   ‚îú‚îÄ‚îÄ alembic/             # Database migration scripts
‚îÇ   ‚îú‚îÄ‚îÄ test_*.py            # Comprehensive test suite (107 tests)
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt     # Python dependencies
‚îÇ   ‚îî‚îÄ‚îÄ README.md            # Backend documentation
‚îú‚îÄ‚îÄ frontend/                # React TypeScript frontend
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ App.tsx          # Main application component
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ AppContext.tsx   # React context & state management
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ContextTemplates.tsx # Template creation component
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ContextTools.tsx # Import/export & filtering tools
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api.ts           # API client with all endpoints
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ types.ts         # TypeScript type definitions
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.tsx        # React entry point
‚îÇ   ‚îú‚îÄ‚îÄ public/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.html       # HTML template
‚îÇ   ‚îú‚îÄ‚îÄ package.json         # Node.js dependencies
‚îÇ   ‚îî‚îÄ‚îÄ tsconfig.json        # TypeScript configuration
‚îú‚îÄ‚îÄ LICENSE                  # MIT License
‚îú‚îÄ‚îÄ THIRD_PARTY_NOTICES      # Third-party dependency licenses
‚îú‚îÄ‚îÄ QUICKSTART.md            # Quick reference guide
‚îú‚îÄ‚îÄ ARCHITECTURE.md          # System architecture documentation
‚îú‚îÄ‚îÄ SECURITY.md              # Security guidelines
‚îú‚îÄ‚îÄ DEPLOYMENT.md            # Production deployment guide
‚îú‚îÄ‚îÄ setup.sh                 # Automated environment setup
‚îú‚îÄ‚îÄ start.sh                 # Start both backend & frontend (with auto-setup)
‚îú‚îÄ‚îÄ stop.sh                  # Stop all services
‚îú‚îÄ‚îÄ start-backend.sh         # Start backend only
‚îú‚îÄ‚îÄ start-frontend.sh        # Start frontend only
‚îú‚îÄ‚îÄ demo.sh                  # Demo with sample data
‚îú‚îÄ‚îÄ CONCEPT.txt              # Original concept document
‚îî‚îÄ‚îÄ README.md                # This file
```

## üöÄ Quick Start

### Prerequisites

- Python 3.8+
- Node.js 16+
- npm or yarn

### Option 1: Automated Setup (Recommended)

The easiest way to get started is using the automated setup script:

```bash
./setup.sh
```

This script will:
- ‚úÖ Check all prerequisites (Python 3, Node.js)
- ‚úÖ Create and configure virtual environment
- ‚úÖ Install all backend dependencies
- ‚úÖ Initialize the database
- ‚úÖ Install all frontend dependencies
- ‚úÖ Detect and fix common issues (broken symlinks, missing packages)

Then start the application:

```bash
./start.sh
```

This will:
- ‚úÖ Automatically run setup if needed
- ‚úÖ Start the backend server on http://localhost:8000
- ‚úÖ Start the frontend development server on http://localhost:3000
- ‚úÖ Open the application in your browser
- ‚úÖ Provide health check verification

To stop all services:

```bash
./stop.sh
```

### Option 2: Manual Setup

#### Backend Setup

1. Navigate to the backend directory:
```bash
cd backend
```

2. Create and activate a virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Configure environment variables:
```bash
cp .env.example .env
# Edit .env with your API keys and database URL
```

5. Initialize the database:
```bash
python init_db.py
```

6. Run the server with example data (optional):
```bash
python -c "from example_data import load_example_data; load_example_data()" && python main.py
```

Or run without example data:
```bash
python main.py
```

The backend will be available at **http://localhost:8000**

API documentation: **http://localhost:8000/docs**

> **Note**: For production deployment with PostgreSQL and pgvector, see [DATABASE.md](backend/docs/DATABASE.md)

#### Frontend Setup

1. Navigate to the frontend directory:
```bash
cd frontend
```

2. Install dependencies:
```bash
npm install
```

3. Start the development server:
```bash
npm start
```

The frontend will be available at **http://localhost:3000**

## üìù Usage Examples

### 1. Using the Web UI

1. Open http://localhost:3000
2. **Configure API Keys**: Click the ‚öôÔ∏è settings button to configure your OpenAI or Anthropic API keys for AI chat functionality
3. Add context units (preferences, decisions, facts, goals) using templates or manual entry
4. Enter a task in the "Generate Prompt" section
5. View the generated prompt with relevant context
6. Copy the prompt to use with any LLM
7. **Use AI Chat**: Get instant AI responses with relevant context automatically included
8. **Import/Export**: Export your contexts to JSON/CSV or import from JSON files

### 2. Using the API

**Create a context:**
```bash
curl -X POST http://localhost:8000/contexts \
  -H "Content-Type: application/json" \
  -d '{
    "type": "preference",
    "content": "I prefer functional programming style",
    "confidence": 0.9,
    "tags": ["programming", "style"]
  }'
```

**List contexts:**
```bash
curl http://localhost:8000/contexts
```

**Generate a prompt:**
```bash
curl -X POST http://localhost:8000/generate-prompt \
  -H "Content-Type: application/json" \
  -d '{
    "task": "Write a function to sort a list",
    "max_context_units": 5
  }'
```

**Ask AI with context (NEW):**
```bash
curl -X POST http://localhost:8000/ai/chat \
  -H "Content-Type: application/json" \
  -d '{
    "task": "Explain the main purpose of this codebase",
    "max_context_units": 5,
    "provider": "openai",
    "model": "gpt-4-turbo-preview"
  }'
```

**View conversation history (NEW):**
```bash
curl http://localhost:8000/ai/conversations
```

### 3. Example Generated Prompt

**Task:** "Write a Python function to calculate fibonacci numbers"

**Generated Prompt:**
```
# Context

## Preferences
- [‚úì] I prefer concise, technical explanations without excessive verbosity
  (Tags: communication, style, technical)
- [‚úì] I like code examples in Python and TypeScript
  (Tags: programming, languages)

## Goals
- [‚úì] Building an AI-powered context management system called ContextPilot
  (Tags: project, ai, context)

## Decisions
- [‚úì] Using FastAPI for backend instead of Django for better async support
  (Tags: architecture, backend, fastapi)

## Facts
- [‚úì] I have experience with vector databases and embeddings
  (Tags: skills, ai, embeddings)

# Task

Write a Python function to calculate fibonacci numbers

# Instructions
Please complete the task above, taking into account the provided context.
Align your response with the stated preferences, goals, and decisions.
```

## üß™ Testing

### Run Backend Tests
```bash
cd backend
python test_api.py
```

### Run Demo Script
```bash
| POST | `/ai/chat` | **NEW**: Generate AI response with context |
| GET | `/ai/conversations` | **NEW**: List conversation history |
| GET | `/ai/conversations/{id}` | **NEW**: Get specific conversation |

For detailed API documentation, see the interactive docs at `/docs` when the server is running.
chmod +x demo.sh
./demo.sh
```

## üîß API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/` | Root endpoint |
| GET | `/health` | Health check |
| GET | `/stats` | Get statistics |
| POST | `/contexts` | Create context unit |
| GET | `/contexts` | List all contexts |
| GET | `/contexts/{id}` | Get specific context |
| PUT | `/contexts/{id}` | Update context |
| DELETE | `/contexts/{id}` | Delete context |
| POST | `/generate-prompt` | Generate contextualized prompt |
| POST | `/generate-prompt/compact` | Generate compact prompt |

## üìä Data Model

### ContextUnit
```typescript
{
  id: string;                    // Unique ID
  type: "preference" | "decision" | "fact" | "goal";
  content: string;               // Natural language description
  confidence: number;            // 0.0 - 1.0
  created_at: string;            // ISO timestamp
  last_used: string | null;      // ISO timestamp
  source: string;                // "manual" or "extracted"
  tags: string[];                // Array of tags
  status: "active" | "superseded";
  superseded_by: string | null;  // ID of replacing context
}
```
SQLAlchemy 2.0 (ORM and database toolkit)
- PostgreSQL / SQLite (persistent storage)
- pgvector (vector similarity search)
- OpenAI API (GPT-4 integration)
- Anthropic API (Claude integration)
- sentence-transformers (embeddings)
- Pydantic (data validation)
- NumPy (vector operations)

**Frontend:**
- React 18
- TypeScript
- Axios (HTTP client)
- CSS3 (styling)

## üìö Documentation

- **[Database Setup](backend/docs/DATABASE.md)**: SQLite and PostgreSQL configuration
- **[AI Integration](backend/docs/AI_INTEGRATION.md)**: OpenAI and Anthropic setup
- **[API Reference](http://localhost:8000/docs)**: Interactive API documentation (when server is running)

## üîÆ Future Enhancements

- [x] Persistent storage (PostgreSQL + pgvector) ‚úÖ
- [x] ChatGPT/Claude API integration ‚úÖ
- [x] Export/import functionality ‚úÖ
- [x] Advanced search and filtering ‚úÖ
- [ ] Automatic context extraction from documents
- [ ] Context decay and reinforcement learning
- [ ] Conflict detection between contexts
- [ ] Browser extension for automatic context capture
- [ ] IDE plugin integration
- [ ] Analytics dashboard
- [ ] Streaming AI responses
- [ ] Multi-turn conversations

## ü§ù Contributing

This is an MVP. Contributions are welcome! Areas for improvement:

1. **Storage**: Replace in-memory store with persistent database
2. **Embeddings**: Add support for other embedding models
3. **UI**: Enhance the interface with better visualizations
4. **Testing**: Add unit tests and integration tests
5. **Documentation**: Improve API documentation

## üìÑ License

See [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- Built with FastAPI and React
- Embeddings powered by sentence-transformers
- Inspired by the need for context-aware AI interactions

---

**Built with ‚ù§Ô∏è for better AI conversations**
