# ContextPilot - Quick Reference

## Installation

```bash
# Clone or navigate to project
cd ContextPilot

# Make scripts executable (macOS/Linux)
chmod +x *.sh

# Start everything
./start.sh
```

## Quick Commands

### Start Both Backend & Frontend
```bash
./start.sh
```

### Start Backend Only
```bash
./start-backend.sh
# Or manually:
cd backend && python3 -m venv venv && source venv/bin/activate
pip install -r requirements.txt
python main.py
```

### Start Frontend Only
```bash
./start-frontend.sh
# Or manually:
cd frontend
npm install
npm start
```

### Run Demo
```bash
./demo.sh
```

### Run Tests
```bash
cd backend
python -m pytest  # All tests
python -m pytest --ignore=test_integration.py  # Unit tests only
python test_dynamic_models.py  # Test model discovery
```

### Model Discovery
```bash
# Discover available models
python3 discover_models.py

# Force model refresh
python3 refresh_models.py --force

# Check current models
python3 demo_dynamic_models.py

# Set up daily auto-discovery (cron)
./update_models.sh
```

### Backup Database
```bash
cd backend
./backup_db.sh  # Create backup
./restore_db.sh  # Restore from backup
```

## URLs

| Service | URL | Description |
|---------|-----|-------------|
| Frontend | http://localhost:3000 | React UI |
| Backend | http://localhost:8000 | API Server |
| API Docs | http://localhost:8000/docs | Swagger UI |
| API Redoc | http://localhost:8000/redoc | ReDoc UI |

## API Endpoints

### Contexts

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/contexts` | Create new context |
| GET | `/contexts` | List all contexts |
| GET | `/contexts/{id}` | Get specific context |
| PUT | `/contexts/{id}` | Update context |
| DELETE | `/contexts/{id}` | Delete context |

### Prompts

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/generate-prompt` | Generate full prompt |
| POST | `/generate-prompt/compact` | Generate compact prompt |

### AI Chat & Conversations

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/ai/chat` | Generate AI response with context |
| GET | `/ai/conversations` | List conversation history |
| GET | `/ai/conversations/{id}` | Get specific conversation |
| DELETE | `/ai/conversations/{id}` | Delete conversation |

### Utilities

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/health` | Health check |
| GET | `/stats` | Get statistics |
| GET | `/settings` | Get current settings |
| POST | `/settings` | Update settings |
| GET | `/` | Root info |

### Model Management

ContextPilot automatically discovers available models from each provider:
- **OpenAI**: Real-time API discovery (when key configured)
- **Anthropic**: Curated current model list
- **Ollama**: Auto-detects locally installed models

Models are cached for 24 hours and refreshed automatically on backend startup.

## cURL Examples

### Create Context
```bash
curl -X POST http://localhost:8000/contexts \
  -H "Content-Type: application/json" \
  -d '{
    "type": "preference",
    "content": "I prefer functional programming",
    "confidence": 0.9,
    "tags": ["programming", "style"]
  }'
```

### List Contexts
```bash
curl http://localhost:8000/contexts
```

### Generate Prompt
```bash
curl -X POST http://localhost:8000/generate-prompt \
  -H "Content-Type: application/json" \
  -d '{
    "task": "Write a sorting function",
    "max_context_units": 5
  }'
```

### Get Statistics
```bash
curl http://localhost:8000/stats
```

### Delete Context
```bash
curl -X DELETE http://localhost:8000/contexts/{id}
```

## Python API Usage

```python
from models import ContextUnit, ContextType
from storage import context_store
from relevance import relevance_engine
from composer import prompt_composer

# Create a context
context = ContextUnit(
    type=ContextType.PREFERENCE,
    content="I prefer async/await over callbacks",
    confidence=0.95,
    tags=["javascript", "async"]
)

# Generate embedding
embedding = relevance_engine.encode(context.content)

# Store it
context_store.add(context, embedding)

# Generate prompt
task = "Write an async function to fetch data"
ranked = relevance_engine.rank_with_keywords(task, context_store, max_results=5)
prompt = prompt_composer.compose(task, ranked)

print(prompt.generated_prompt)
```

## TypeScript API Usage

```typescript
import { contextAPI } from './api';
import { ContextType } from './types';

// Create context
const newContext = await contextAPI.createContext({
  type: ContextType.PREFERENCE,
  content: "I prefer TypeScript over JavaScript",
  confidence: 0.9,
  tags: ["programming", "languages"]
});

// List contexts
const contexts = await contextAPI.listContexts();

// Generate prompt
const result = await contextAPI.generatePrompt({
  task: "Create a new component",
  max_context_units: 5
});

console.log(result.generated_prompt);
```

## Context Types

| Type | Use For | Example |
|------|---------|---------|
| `preference` | Personal preferences | "I prefer Python over Java" |
| `decision` | Past decisions | "Using PostgreSQL for database" |
| `fact` | Factual information | "I work remotely in PST timezone" |
| `goal` | Objectives | "Build an MVP in 2 weeks" |

## Configuration

### Option 1: Settings UI (Recommended)

The easiest way to configure API keys:

1. Open http://localhost:3000
2. Click the ‚öôÔ∏è settings button in the header
3. Enter your OpenAI or Anthropic API key
4. Configure AI model and parameters
5. Click "Save Settings"

No restart required - settings apply immediately!

### Option 2: Environment Files

#### Backend (.env)
```bash
HOST=0.0.0.0
PORT=8000
EMBEDDING_MODEL=all-MiniLM-L6-v2
LOG_LEVEL=INFO

# AI Configuration (or use Settings UI)
CONTEXTPILOT_OPENAI_API_KEY=sk-your-key-here
CONTEXTPILOT_ANTHROPIC_API_KEY=sk-ant-your-key-here
```

#### Frontend (.env)
```bash
REACT_APP_API_URL=http://localhost:8000
```

## Troubleshooting

### Backend won't start
```bash
# Check Python version (need 3.8+)
python3 --version

# Recreate venv
rm -rf backend/venv
cd backend && python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### Frontend won't start
```bash
# Check Node version (need 16+)
node --version

# Clear and reinstall
cd frontend
rm -rf node_modules package-lock.json
npm install
```

### Port already in use
```bash
# Backend (8000)
lsof -ti:8000 | xargs kill -9

# Frontend (3000)
lsof -ti:3000 | xargs kill -9
```

### CORS errors
- Make sure backend is running on port 8000
- Check CORS_ORIGINS in backend/main.py
- Verify frontend is using correct API URL

## File Structure

```
ContextPilot/
‚îú‚îÄ‚îÄ backend/                   # FastAPI backend
‚îÇ   ‚îú‚îÄ‚îÄ main.py               # API server
‚îÇ   ‚îú‚îÄ‚îÄ models.py             # Data models
‚îÇ   ‚îú‚îÄ‚îÄ storage.py            # Storage layer
‚îÇ   ‚îú‚îÄ‚îÄ relevance.py          # Relevance engine
‚îÇ   ‚îú‚îÄ‚îÄ composer.py           # Prompt composer
‚îÇ   ‚îú‚îÄ‚îÄ example_data.py       # Example data
‚îÇ   ‚îú‚îÄ‚îÄ test_api.py           # Tests
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt      # Dependencies
‚îú‚îÄ‚îÄ frontend/                  # React frontend
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ App.tsx           # Main component
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api.ts            # API client
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ types.ts          # TypeScript types
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ App.css           # Styles
‚îÇ   ‚îú‚îÄ‚îÄ public/
‚îÇ   ‚îî‚îÄ‚îÄ package.json          # Dependencies
‚îú‚îÄ‚îÄ ARCHITECTURE.md            # System design
‚îú‚îÄ‚îÄ EXAMPLES.md                # Usage examples
‚îú‚îÄ‚îÄ README.md                  # Main documentation
‚îî‚îÄ‚îÄ *.sh                       # Start scripts
```

## Dependencies

### Backend
- fastapi==0.109.0
- uvicorn[standard]==0.27.0
- pydantic==2.5.3
- sentence-transformers==2.3.1
- numpy==1.26.3
- torch==2.1.2

### Frontend
- react@18.2.0
- typescript@4.9.5
- axios@1.6.5

## Performance Tips

1. **First run is slow** - Downloads ML model (~80MB)
2. **Subsequent runs are fast** - Model is cached
3. **Embedding generation** - ~50-100ms per text
4. **Similarity search** - O(n) with n contexts
5. **Keep contexts focused** - Better relevance with specific contexts

## Best Practices

### Context Management
- ‚úÖ Be specific in content
- ‚úÖ Use descriptive tags
- ‚úÖ Set appropriate confidence
- ‚úÖ Supersede outdated contexts
- ‚ùå Don't create duplicate contexts
- ‚ùå Don't use vague descriptions

### Prompt Generation
- ‚úÖ Describe task clearly
- ‚úÖ Adjust max_context_units as needed
- ‚úÖ Review generated prompts
- ‚ùå Don't rely on too few contexts
- ‚ùå Don't overload with irrelevant contexts

## Common Use Cases

### Software Development
```bash
# Task: "Implement user authentication"
# Pulls: Tech stack decisions, security preferences, coding style

# Task: "Write unit tests"
# Pulls: Testing framework decisions, coverage goals, style preferences
```

### Writing
```bash
# Task: "Write project documentation"
# Pulls: Communication style, audience preferences, format decisions

# Task: "Draft team update email"
# Pulls: Communication preferences, project goals, team context
```

### Learning
```bash
# Task: "Explain React hooks"
# Pulls: Learning style preferences, experience level, related knowledge
```

## Next Steps

1. **Explore the UI** - http://localhost:3000
2. **Add your contexts** - Start with 5-10 key preferences
3. **Test prompt generation** - Try different tasks
4. **Review EXAMPLES.md** - See detailed use cases
5. **Read ARCHITECTURE.md** - Understand the system

## Support

- üìñ Documentation: See README.md
- üèóÔ∏è Architecture: See ARCHITECTURE.md
- üí° Examples: See EXAMPLES.md
- üêõ Issues: Check terminal logs
- üîß Debugging: Use /health endpoint

## License

See LICENSE file for details.
